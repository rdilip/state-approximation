{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NOTE: I thought Google's tensor network library might help with some of what I'm doing. My conclusion is that it is a promising library, but honestly is not very useful unless it starts caching large contractions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensornetwork as tn\n",
    "import numpy as np\n",
    "from pprint import pprint\n",
    "from tebd import tebd\n",
    "from misc import mps_2form, mps_overlap, mpo_on_mpo\n",
    "from state_approximation import mps2mpo, mpo2mps, multiple_diagonal_expansions,\\\n",
    "                                diagonal_expansion, contract_diagonal_expansion,\\\n",
    "                                contract_series_diagonal_expansions, mpo_on_mps,\\\n",
    "                                entanglement_entropy\n",
    "from moses_simple import moses_move as moses_move_simple\n",
    "import matplotlib.pyplot as plt\n",
    "from disentanglers import disentangle_S2\n",
    "import scipy\n",
    "from scipy.stats import unitary_group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_network(network, labels=None):\n",
    "    \"\"\" Given a tensor network -- either an MPO or an MPS -- return a list of tn.Node\n",
    "    with correct connections. \n",
    "    Parameters\n",
    "    ----------\n",
    "    network: List\n",
    "        list of np.Array with format either pSN or WESN. \n",
    "    labels : List\n",
    "        A list of str to add as labels to each node.\n",
    "    \"\"\"\n",
    "    if type(network[0]) == tn.Node:\n",
    "        return network\n",
    "    tn_network = np.array([tn.Node(i) for i in network])\n",
    "    L = len(network)\n",
    "    if labels:\n",
    "        for i in range(L):\n",
    "            tn_network[i].name = str(labels[i])\n",
    "    if tn_network[0].get_rank() == 3: #MPS\n",
    "        for i in range(L-1):\n",
    "            tn_network[i][-1] ^ tn_network[i+1][1]\n",
    "    if tn_network[0].get_rank() == 4: #MPO\n",
    "        for i in range(L-1):\n",
    "            tn_network[i][-1] ^ tn_network[i+1][2]\n",
    "    else:\n",
    "        raise ValueError(\"Unrecognized tensor network.\")\n",
    "    return tn_network\n",
    "\n",
    "def _mpo_on_mpo_straight(mpoL, mpoR):\n",
    "    \"\"\" mpo on mpo, assumes inputs are lists of tensor networks with\n",
    "    vertical contractions already performed \"\"\"\n",
    "    mpo_out = []\n",
    "    L = len(mpoL)\n",
    "    for i in range(L):\n",
    "        mpoL[i][1] ^ mpoR[i][0]\n",
    "        tensor_out = tn.contract_between(mpoL[i], mpoR[i])\n",
    "        tn.flatten_edges([tensor_out[1], tensor_out[4]])\n",
    "        tn.flatten_edges([tensor_out[1], tensor_out[3]])\n",
    "        mpo_out.append(tensor_out)\n",
    "    return mpo_out\n",
    "\n",
    "def _mpo_on_mpo_shifted(mpoL, mpoR):\n",
    "    \"\"\" mpo on mpo with the shifted protocol. Does this by contracting the\n",
    "    entire tensor then using a series of qr decompositions to return to\n",
    "    isometric form. \n",
    "    \"\"\"\n",
    "    L = len(mpoL)\n",
    "    mpoL[0][1] ^ mpoR[0][2]\n",
    "    for i in range(L-1):\n",
    "        mpoL[i+1][1] ^ mpoR[i][0]\n",
    "    mpoL[L-1][3] ^ mpoR[L-1][0]\n",
    "    \n",
    "    edge_list = []\n",
    "    for i in range(L):\n",
    "        edge_list.extend(ordered_get_all_dangling([mpoL[i], mpoR[i]]))\n",
    "        \n",
    "    output = tn.contractors.auto(tn.reachable(mpoL[0]), edge_list)\n",
    "    out = []\n",
    "    node_q, output = tn.split_node_qr(output, left_edges=output[0:3], right_edges=output[3:])\n",
    "    out.append(node_q.reorder_axes([0,2,1,3]))\n",
    "    for i in range(L-2):\n",
    "        node_q, output = tn.split_node_qr(output, left_edges=output[:3], right_edges=output[3:])\n",
    "        out.append(node_q.reorder_axes([1,2,0,3]))\n",
    "    out.append(output.reorder_axes([1,2,0,3]))\n",
    "    return out\n",
    "\n",
    "def _mpo_on_mpo_shifted_efficient(mpoL, mpoR):\n",
    "    \"\"\" mpo_on_mpo with the efficient shifted protocol. This should be your default.\n",
    "    Only needs to do qr decompositions on the first and last tensor.\n",
    "    \"\"\"\n",
    "    L = len(mpoL)\n",
    "    mpo_out = []\n",
    "    for i in range(2, L-1):\n",
    "        mpoL[i][1] ^ mpoR[i-1][0]\n",
    "        mpo_out.append(tn.contract_between(mpoL[i], mpoR[i-1]))\n",
    "    for i in range(2,L-1):\n",
    "        tn.flatten_edges([mpo_out[i-2][1], mpo_out[i-2][4]])\n",
    "        tn.flatten_edges([mpo_out[i-2][1], mpo_out[i-2][3]])\n",
    "    \n",
    "    mpoL[1][1] ^ mpoR[0][0]\n",
    "    mpoL[0][1] ^ mpoR[0][2]\n",
    "    \n",
    "    first_tensor = tn.contract_between(mpoL[0], mpoL[1])\n",
    "    first_tensor = tn.contract_between(first_tensor, mpoR[0])\n",
    "    first_tensor, second_tensor = tn.split_node_qr(first_tensor, \n",
    "                                                   left_edges=[first_tensor[0], first_tensor[1]],\n",
    "                                                   right_edges=[first_tensor[i] for i in [2,4,3,5]]\n",
    "                                                )\n",
    "    first_shape = first_tensor.shape\n",
    "    first_tensor = tn.Node(first_tensor.tensor.reshape((*first_shape, 1)))\n",
    "    first_tensor = tn.transpose(first_tensor, [0,3,1,2])\n",
    "    \n",
    "    tn.flatten_edges([second_tensor[3], second_tensor[4]])\n",
    "    second_tensor = tn.transpose(second_tensor, [1,2,0,3])\n",
    "    mpo_out = [first_tensor, second_tensor] + mpo_out\n",
    "    \n",
    "\n",
    "    \n",
    "    mpoL[L-1][3] ^ mpoR[L-1][0]\n",
    "    mpoL[L-1][1] ^ mpoR[L-2][0]\n",
    "    first_tensor = tn.contract_between(mpoL[L-1], mpoR[L-2])\n",
    "    first_tensor = tn.contract_between(first_tensor, mpoR[L-1])\n",
    "    first_tensor, second_tensor = tn.split_node_qr(first_tensor,\n",
    "                                  left_edges=[first_tensor[i] for i in range(4)],\n",
    "                                  right_edges=[first_tensor[i] for i in [4,5]])\n",
    "    second_tensor = tn.flatten_edges([second_tensor[3], second_tensor[4]])\n",
    "    second_tensor = tn.transpose(second_tensor, [1,2,0,3])\n",
    "    mpo_out.extend([first_tensor, second_tensor])\n",
    "    return(mpo_out)\n",
    "\n",
    "def mpo_on_mpo_generalized(mpoL, mpoR, mode='shifted'):\n",
    "    \"\"\" Contracts two mpos with shift for series of quantum gates. Really contracts the whole \n",
    "    tensor then splits it using a series of QRs, so may end up being quite expensive... but\n",
    "    is probably the correct way to do it.\n",
    "    Parameters\n",
    "    ----------\n",
    "    mpoL:\n",
    "        Left mpo\n",
    "    mpoR:\n",
    "        Right mpo with leg format \n",
    "    mode:\n",
    "        Contraction method. The options are straight, shifted, and shifted_efficient. The\n",
    "        first is a vanilla mpo on mpo, the second is the fancy shifting we're doing, but\n",
    "        we contract the whole network and reconstruct the mpo. The third only does QRs\n",
    "        on the first and the last few tensors.\n",
    "    \"\"\"\n",
    "    mpoL = process_network(mpoL.copy())\n",
    "    mpoR = process_network(mpoR.copy())\n",
    "    \n",
    "    if mode == 'shifted':\n",
    "        return _mpo_on_mpo_shifted(mpoL, mpoR)\n",
    "    elif mode == 'shifted_efficient':\n",
    "        return _mpo_on_mpo_shifted_efficient(mpoL, mpoR)\n",
    "    elif mode == 'straight':\n",
    "        return _mpo_on_mpo_straight(mpoL, mpoR)\n",
    "    else:\n",
    "        raise ValueError(\"Invalid mode\")\n",
    "    \n",
    "def series_contraction(As, Lambda):\n",
    "    output = As[0]\n",
    "    for A in As[1:]:\n",
    "        output = mpo_on_mpo(output, A)\n",
    "    return mpo_on_mpo(output, Lambda)\n",
    "\n",
    "\n",
    "def remove_dangling_legs(mps):\n",
    "    \"\"\" Removes the dangling legs on an mps. \"\"\"\n",
    "    d1, chiL1, chiR1 = mps[0].shape\n",
    "    d2, chiL2, chiR2 = mps[-1].shape\n",
    "    assert chiL1 == chiR2 == 1\n",
    "    mps[0] = mps[0].reshape((d1, chiR1))\n",
    "    mps[-1] = mps[-1].reshape((d2, chiL2))\n",
    "    return mps\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _sweep_disentangle_single_pass(Psi):\n",
    "    L = len(Psi)\n",
    "    Us = []\n",
    "    for i in range(L-1):\n",
    "        theta = np.tensordot(Psi[i], Psi[i+1], [2,1]).transpose([1,0,2,3])\n",
    "        theta, U, Ss = disentangle_S2(theta, max_iter=1, eps=1.e-16)\n",
    "        chiL, d1, d2, chiR = theta.shape\n",
    "        q, r = np.linalg.qr(theta.reshape(chiL*d1, chiR*d2))\n",
    "        Psi[i] = q.reshape((chiL, d1, -1)).transpose([1,0,2])\n",
    "        Psi[i+1] = r.reshape((-1, d2, chiR)).transpose([1,0,2])\n",
    "        Us.append(U)\n",
    "    return Psi, Us\n",
    "\n",
    "def sweep_disentangle_one_side(Lambda):\n",
    "    \"\"\" \n",
    "    Performs a back and forth sweep of disentangling on an MPS Lambda.\n",
    "    Parameters\n",
    "    ----------\n",
    "    Lambda : list of np.Array\n",
    "        Physical wavefunction\n",
    "    Returns\n",
    "    -------\n",
    "    Psi : List of np.Array \n",
    "        Disentanglined wavefunction\n",
    "    U1, U2 : np.Arrays\n",
    "        List of unitaries. U1 is the list of unitaries on the forward sweep, U2\n",
    "        is the list on the back sweep.\n",
    "        NOTE: U2 assumes that we're on the back sweep...\n",
    "    \"\"\"\n",
    "    Psi = Lambda.copy()\n",
    "    if Psi[0].ndim == 4:\n",
    "        Psi = mpo2mps(Lambda)\n",
    "    Psi, U1 = _sweep_disentangle_single_pass(Psi)\n",
    "    Psi = [psi.transpose([0,2,1]) for psi in Psi[::-1]]\n",
    "    Psi, U2 = _sweep_disentangle_single_pass(Psi)\n",
    "    Psi = [psi.transpose([0,2,1]) for psi in Psi[::-1]]\n",
    "    return mps2mpo(Psi), [U1, U2]\n",
    "\n",
    "def sweep_and_disentangle(A0, Lambda):\n",
    "    \"\"\"\n",
    "    Given A0, Lambda s.t. Psi = A0.Lambda, performs a single sweep back and forth\n",
    "    to disentangle Lambda further.\n",
    "    Parameters\n",
    "    ----------\n",
    "    A0 : list of np.Array\n",
    "    Lambda : list of np.Array\n",
    "    Returns\n",
    "    -------\n",
    "    A0, Lambda : Disentangled versions\n",
    "    \"\"\"\n",
    "    Lambda = [psi.transpose([0,1,3,2]) for psi in Lambda[::-1]]\n",
    "    Lambda, [U1, U2] = sweep_disentangle_one_side(Lambda)\n",
    "    Lambda = [psi.transpose([0,1,3,2]) for psi in Lambda[::-1]]\n",
    "\n",
    "\n",
    "    U1 = [U.conj() for U in U1[::-1]]\n",
    "    U2 = [U.conj() for U in U2[::-1]]\n",
    "    #U1 = None\n",
    "    #U2 = None\n",
    "    A0 = split_and_apply_unitary(A0, U1, form='A')\n",
    "    A0 = split_and_apply_unitary(A0, U2, form='B')\n",
    "    return A0, Lambda\n",
    "\n",
    "def get_eye(d1, d2):\n",
    "    return np.kron(np.eye(d1), np.eye(d2)).reshape([d1,d2,d1,d2])\n",
    "\n",
    "def split_and_apply_unitary(Psi, Us, form='B'):\n",
    "    \"\"\" Given a wavefunction Psi and a list of two site unitaries U, sweeps along\n",
    "    the wavefunction applying all the Us. This is designed to act on A0 in the \n",
    "    shifted regime -- so it does not act on the first  tensor, and acts on two\n",
    "    legs of the last tensor. Starting from A form reverses this, but the broken\n",
    "    symmetry due to the shift means we can't just reverse the wavefunction.\n",
    "    \n",
    "    TODO: refactor this\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    Psi : list of np.Array\n",
    "        The wavefunction\n",
    "    Us : list of np.Array\n",
    "        List of L-1 two site unitaries\n",
    "    form : str\n",
    "        Starting form, either A (arrows pointing up) or B (arrows pointing down)\n",
    "    \n",
    "    Ensure that the zeroth leg is acted on by the unitary.\n",
    "    \"\"\"\n",
    "    L = len(Psi)\n",
    "    assert form in ['A', 'B']\n",
    "           \n",
    "    if form == 'A':\n",
    "        Psi = [psi.transpose([0,1,3,2]) for psi in Psi[::-1]]\n",
    "        if Us is None:\n",
    "            Us = []\n",
    "            Us.append(get_eye(Psi[0].shape[2], Psi[0].shape[1]))\n",
    "            for i in range(0, L-2):\n",
    "                shape = (Psi[i].shape[0], Psi[i+1].shape[0])\n",
    "                Us.append(get_eye(*shape))\n",
    "                \n",
    "        Psi[0] = np.tensordot(Psi[0], Us[0], [[1,3],[2,3]]).transpose([0,2,1,3])\n",
    "        \n",
    "        for i in range(0, L-2):\n",
    "            psi = np.tensordot(Psi[i], Psi[i+1], [3, 2])\n",
    "            W1,E1,S1,W2,E2,N2 = psi.shape\n",
    "            \n",
    "\n",
    "            \n",
    "            psi = np.tensordot(psi, Us[i+1], [[1,4],[2,3]]).transpose([0,4,1,2,5,3])\n",
    "                \n",
    "            psi = psi.reshape(W1*E1*S1, W2*E2*N2)\n",
    "            u, s, v = np.linalg.svd(psi, full_matrices=False)\n",
    "\n",
    "            s = s[s > 1.e-10]\n",
    "            chi_max = len(s)\n",
    "            q = u[:,:chi_max]\n",
    "            v = v[:chi_max,:]\n",
    "            r = (np.diag(s) @ v)\n",
    "            Psi[i] = q.reshape(W1,E1,S1,chi_max)\n",
    "            Psi[i+1] = r.reshape(chi_max,W2,E2,N2).transpose([1,2,0,3])\n",
    "        Psi = [psi.transpose([0,1,3,2]) for psi in Psi[::-1]]\n",
    "        return Psi\n",
    "    \n",
    "    else:\n",
    "        if Us is None:\n",
    "            Us = []\n",
    "            for i in range(1, L-1):\n",
    "                shape = (Psi[i].shape[1], Psi[i+1].shape[1])\n",
    "                Us.append(get_eye(*shape))\n",
    "            Us.append(get_eye(Psi[L-1].shape[1], Psi[L-1].shape[3]))\n",
    "        for i in range(0,L-1):\n",
    "            psi = np.tensordot(Psi[i], Psi[i+1], [3, 2])\n",
    "            W1,E1,S1,W2,E2,N2 = psi.shape\n",
    "            \n",
    "            if i > 0:\n",
    "                psi = np.tensordot(psi, Us[i-1], [[1,4],[2,3]]).transpose([0,4,1,2,5,3])\n",
    "            \n",
    "            psi = psi.reshape(W1*E1*S1, W2*E2*N2)\n",
    "            u, s, v = np.linalg.svd(psi, full_matrices=False)\n",
    "\n",
    "            s = s[s > 1.e-10]\n",
    "            chi_max = len(s)\n",
    "            q = u[:,:chi_max]\n",
    "            v = v[:chi_max,:]\n",
    "            r = (np.diag(s) @ v)\n",
    "            Psi[i] = q.reshape(W1,E1,S1,chi_max)\n",
    "            Psi[i+1] = r.reshape(chi_max,W2,E2,N2).transpose([1,2,0,3])\n",
    "\n",
    "        Psi[L-1] = np.tensordot(Psi[L-1], Us[-1], [[1,3],[2,3]]).transpose([0,2,1,3])\n",
    "        return Psi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 662,
   "metadata": {},
   "outputs": [],
   "source": [
    "tebd_state, _, _ = tebd(10, 1.5, 0.1)\n",
    "Psi = mps2mpo(tebd_state.copy())\n",
    "Lambda = Psi.copy()\n",
    "As, Lambda, Ss, Lambdas = multiple_diagonal_expansions(Psi,200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 663,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.0000000000006972, 1.0000000000006972)"
      ]
     },
     "execution_count": 663,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#out = contract_diagonal_expansion(As[0], Lambda)\n",
    "out = contract_series_diagonal_expansions(As, Lambda)\n",
    "np.linalg.norm(mps_overlap(Psi, out)), mps_overlap(Psi, out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "def contract_mpo(mpo):\n",
    "    L = len(mpo)\n",
    "    psi = mpo[0]\n",
    "    for i in range(1, L):\n",
    "        psi = np.tensordot(psi, mpo[i], [-1,2])\n",
    "    return psi\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.047095146989858054\n",
      "1.384817438467499e-05\n"
     ]
    }
   ],
   "source": [
    "As, Lambda, Ss, fidelity, cp, Lambdas = multiple_diagonal_expansions(Psi,200)\n",
    "print(entanglement_entropy(Lambda))\n",
    "for i in range(2000):\n",
    "    Lambda, _ = sweep_disentangle_one_side(Lambda)\n",
    "print(entanglement_entropy(Lambda))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9518665013167418\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(-0.11306510428076419-0.2617473053128689j)"
      ]
     },
     "execution_count": 390,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "As, Lambda, Ss, fidelity, cp, Lambdas = multiple_diagonal_expansions(Psi,1)\n",
    "A = As[-1]\n",
    "out = contract_diagonal_expansion(A, Lambda)\n",
    "print(mps_overlap(Psi, out))\n",
    "#print(entanglement_entropy(Lambda))\n",
    "Lambda = [psi.transpose([0,1,3,2]) for psi in Lambda[::-1]]\n",
    "A = [a.transpose([0,1,3,2]) for a in A[::-1]]\n",
    "#Lambda = mpo2mps(mps_2form(Lambda, 'B'))\n",
    "L = len(Lambda)\n",
    "#print(L)\n",
    "Us = []\n",
    "for i in range(3):\n",
    "    psi = np.tensordot(Lambda[i], Lambda[i+1], [3,2])\n",
    "    W1,E1,S1,W2,E2,N2 = psi.shape\n",
    "    #theta, U, _ = disentangle_S2(theta)\n",
    "    U = unitary_group.rvs(4).reshape([2]*4)\n",
    "    \n",
    "    #theta = psi.reshape(S1*E1, W1, W2, E2*N2)\n",
    "    theta = psi\n",
    "    if i % 2 == 0:\n",
    "        theta = np.tensordot(psi, U, [[0,3],[3,2]]).transpose([4,0,1,5,2,3])\n",
    "        #theta = np.tensordot(U, theta, [[2,3],[1,2]]).transpose([2,0,1,3])\n",
    "\n",
    "    psi = theta.reshape(S1*E1*W1, E2*N2*W2)\n",
    "    Us.append(U)\n",
    "    u, s, v = np.linalg.svd(psi, full_matrices=False)\n",
    "\n",
    "\n",
    "    s = s[s > 1.e-10]\n",
    "    chi_max = len(s)\n",
    "    psi = u[:,:chi_max]\n",
    "    v = v[:chi_max,:]\n",
    "    v = (np.diag(s) @ v)\n",
    "    Lambda[i] = psi.reshape(W1,E1,S1,chi_max)\n",
    "    Lambda[i+1] = v.reshape(chi_max,W2,E2,N2).transpose([1,2,0,3])\n",
    "    if i == 0:\n",
    "        A[0] = np.tensordot(A[0], U.conj(), [[2,1],[2,3]]).transpose([0,3,2,1])\n",
    "    else:\n",
    "        psi = np.tensordot(A[i-1], A[i], [3,2])\n",
    "        W1,E1,S1,W2,E2,N2 = psi.shape\n",
    "        theta = psi.reshape(S1*W1, E1, E2, W2*N2)\n",
    "\n",
    "\n",
    "        #theta, U, _ = disentangle_S2(theta)\n",
    "        if i % 2 == 0:\n",
    "            theta = np.tensordot(U.conj(), theta, [[3,2],[1,2]]).transpose([2,0,1,3])\n",
    "\n",
    "        psi = theta.reshape(S1*E1*W1, E2*N2*W2)\n",
    "        u, s, v = np.linalg.svd(psi, full_matrices=False)\n",
    "\n",
    "\n",
    "        s = s[s > 1.e-10]\n",
    "        chi_max = len(s)\n",
    "        psi = u[:,:chi_max]\n",
    "        v = v[:chi_max,:]\n",
    "        v = (np.diag(s) @ v)\n",
    "        A[i-1] = psi.reshape(W1,E1,S1,chi_max)\n",
    "        A[i] = v.reshape(chi_max,W2,E2,N2).transpose([1,2,0,3])\n",
    "\n",
    "        \n",
    "A = [psi.transpose([0,1,3,2]) for psi in A[::-1]]        \n",
    "Lambda = [psi.transpose([0,1,3,2]) for psi in Lambda[::-1]]\n",
    "#A = split_and_apply_unitary(A, Us)\n",
    "out = contract_diagonal_expansion(A, Lambda)\n",
    "#print(entanglement_entropy(Lambda))\n",
    "mps_overlap(Psi, out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ==============="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 448,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from copy import deepcopy\n",
    "\n",
    "a_shape = [(2, 1, 1, 2), (2, 2, 2, 2)]\n",
    "lambda_shape = [(2, 1, 1, 2), (2, 1, 2, 4)]\n",
    "A1 = [np.random.rand(*shape) for shape in a_shape]\n",
    "Lambda = [np.random.rand(*shape) for shape in lambda_shape]\n",
    "A2 = deepcopy(A1)\n",
    "Lambda2 = deepcopy(Lambda)\n",
    "def process_mpos(mpo):\n",
    "    tn_mpo = [tn.Node(i) for i in mpo]\n",
    "    for i in range(len(mpo)-1):\n",
    "        tn_mpo[i][-1] ^ tn_mpo[i+1][2]\n",
    "    return tn_mpo\n",
    "import sys\n",
    "def mpo_on_mpo(mpoL, mpoR):\n",
    "    L = len(mpoL)\n",
    "    mpoL[0][1] ^ mpoR[0][2]\n",
    "    for i in range(L-1):\n",
    "        mpoL[i+1][1] ^ mpoR[i][0]\n",
    "    mpoL[L-1][3] ^ mpoR[L-1][0]\n",
    "    \n",
    "    edge_list = []\n",
    "    for i in range(L):\n",
    "        edge_list.extend(ordered_get_all_dangling([mpoL[i], mpoR[i]]))\n",
    "    output = tn.contractors.auto(tn.reachable(mpoL[0]), output_edge_order=edge_list)\n",
    "\n",
    "    return output\n",
    "\n",
    "def ordered_get_all_dangling(nodes):\n",
    "    edges = []\n",
    "    for node in nodes:\n",
    "        for edge in node.edges:\n",
    "            if edge.is_dangling():\n",
    "                edges.append(edge)\n",
    "    return edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_mpo_network(lenv, renv, mpo):\n",
    "    all_mpos = [[],[],[]]\n",
    "    dl =  lenv[0].shape[0]\n",
    "    L = len(mpo)\n",
    "    for i in range(L):\n",
    "        all_mpos[0].append(tn.Node(lenv[i], name=f\"lenv_{i}\"))\n",
    "        all_mpos[1].append(tn.Node(mpo[i], name=f\"mpo_{i}\"))\n",
    "        all_mpos[2].append(tn.Node(renv[i], name=f\"renv_{i}\"))\n",
    "    for i in range(L-1):\n",
    "        for j in range(3):\n",
    "            all_mpos[j][i][3] ^ all_mpos[j][i+1][2]\n",
    "            \n",
    "    for i in range(1, L):\n",
    "        all_mpos[0][i][1] ^ all_mpos[1][i-1][0]\n",
    "        all_mpos[1][i][1] ^ all_mpos[2][i-1][0]\n",
    "        \n",
    "    all_mpos[0][L-1][3] ^ all_mpos[1][L-1][0]\n",
    "    all_mpos[1][L-1][3] ^ all_mpos[2][L-1][0]\n",
    "    \n",
    "    all_mpos[0][0][1] ^ all_mpos[1][0][2]\n",
    "    all_mpos[1][0][1] ^ all_mpos[2][0][2]\n",
    "    \n",
    "    return(all_mpos)\n",
    "\n",
    "def setup_environment(all_mpos, i, mps_left, mps_right):\n",
    "    \"\"\" Removes node i, contracts \"\"\"\n",
    "    L = len(mps_left)\n",
    "    mps_L, all_mpos, mps_R = exp_val_mpo(mps_left, mps_right, all_mpos)\n",
    "    \n",
    "    #edge_order = []\n",
    "    #edge_order.extend([all_mpos[0][i][0] for i in range(L)])\n",
    "    #edge_order.extend([all_mpos[2][i][1] for i in range(L)])\n",
    "\n",
    "    #edge_order.append(all_mpos[0][0][2])\n",
    "    #edge_order.append(all_mpos[2][-1][3])\n",
    "    \n",
    "    output = tn.contractors.auto(tn.reachable(all_mpos[0][0]))\n",
    "    return(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "def contract_mps(mps):\n",
    "    t = mps[0]\n",
    "    d = mps[0].shape[0]\n",
    "    for i in range(1, len(mps)):\n",
    "        t = np.tensordot(t, mps[i], [-1, 1])\n",
    "    return t.reshape([d]*len(mps))\n",
    "\n",
    "def tensor_overlap(t1, t2):\n",
    "    assert t1.shape == t2.shape\n",
    "    return np.tensordot(t1, t2, [range(t1.ndim), range(t2.ndim)])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
